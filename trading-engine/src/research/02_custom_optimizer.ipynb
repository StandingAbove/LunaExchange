{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7771201b-e61d-405f-b840-67d58d573a97",
      "metadata": {},
      "source": [
        "# This specific notebook is outdated as of 10/21/2025.\n",
        "## TODO: Redesign notebook to use new optimizer framework"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "initial_id",
      "metadata": {},
      "outputs": [],
      "source": [
        "import datetime as dt\n",
        "import polars as pl\n",
        "from trading_engine.core import (\n",
        "    read_data, create_model_state, orchestrate_model_backtests,\n",
        "    orchestrate_model_simulations, orchestrate_portfolio_aggregation,\n",
        "    orchestrate_portfolio_optimizations, orchestrate_portfolio_simulations\n",
        ")\n",
        "from trading_engine.models import MODELS\n",
        "from trading_engine.optimizers import OPTIMIZERS\n",
        "\n",
        "from trading_engine.model_state.registry import momentum\n",
        "from common.constants import ProcessingMode\n",
        "\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ce8e6a4-e873-41f8-b8d8-403bacf2ae3b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define your aggregator (this is actually an aggregator, not an optimizer!)\n",
        "\n",
        "import datetime as _dt\n",
        "from typing import Callable, Dict, List\n",
        "\n",
        "import polars as pl\n",
        "from polars import LazyFrame\n",
        "\n",
        "_EPS = 1e-9\n",
        "\n",
        "\n",
        "def MinAvgDrawdownAggregator(window_days: int = 90) -> Callable[[Dict[str, LazyFrame], Dict], LazyFrame]:\n",
        "    \"\"\"\n",
        "    Build a portfolio by weighting model insights inversely to their average drawdown\n",
        "    over the last `window_days`. Models with lower recent drawdown get higher weight.\n",
        "    \"\"\"\n",
        "\n",
        "    def _avg_drawdown_recent(metrics_df: pl.DataFrame) -> float:\n",
        "        if metrics_df is None or metrics_df.is_empty():\n",
        "            return float(\"inf\")\n",
        "\n",
        "        # Standardize date to pl.Date\n",
        "        dt = metrics_df.get_column(\"date\")\n",
        "        if dt.dtype == pl.Utf8:\n",
        "            metrics_df = metrics_df.with_columns(\n",
        "                pl.col(\"date\").str.strptime(pl.Date, strict=False).alias(\"date\")\n",
        "            )\n",
        "        elif dt.dtype == pl.Datetime:\n",
        "            metrics_df = metrics_df.with_columns(pl.col(\"date\").dt.date().alias(\"date\"))\n",
        "        # If already pl.Date, leave as-is.\n",
        "\n",
        "        # Window: last `window_days` calendar days from max date\n",
        "        max_d = metrics_df.select(pl.col(\"date\").max()).item()\n",
        "        if max_d is None:\n",
        "            return float(\"inf\")\n",
        "        start = max_d - _dt.timedelta(days=window_days)\n",
        "\n",
        "        # Drawdown magnitude (use abs in case stored negative)\n",
        "        win = metrics_df.filter(pl.col(\"date\") >= pl.lit(start))\n",
        "        if win.is_empty():\n",
        "            win = metrics_df  # fallback to full history\n",
        "\n",
        "        val = win.select(pl.col(\"drawdown\").abs().mean()).item()\n",
        "        if val is None or not (val == val):  # NaN check\n",
        "            return float(\"inf\")\n",
        "        return float(val)\n",
        "\n",
        "    def _coef_from_avg_dd(avg_dd: float) -> float:\n",
        "        # Lower avg drawdown => higher coefficient. Guard with epsilon.\n",
        "        if avg_dd == float(\"inf\"):\n",
        "            return 0.0\n",
        "        return 1.0 / (_EPS + max(avg_dd, 0.0))\n",
        "\n",
        "    def run(model_insights: Dict[str, LazyFrame], backtest_results: Dict) -> LazyFrame:\n",
        "        if not model_insights:\n",
        "            return pl.DataFrame({\"date\": []}).lazy()\n",
        "\n",
        "        # 1) Compute per-model coefficients from backtest_metrics\n",
        "        coefs: Dict[str, float] = {}\n",
        "        for mname, lf in model_insights.items():\n",
        "            metrics = None\n",
        "            if mname in backtest_results:\n",
        "                # New structure: backtest_results[mname] = {\"full_backtest_results\": {...}, \"backtest_results\": {...}}\n",
        "                # Use full_backtest_results for aggregators (has full history)\n",
        "                full_results = backtest_results[mname].get(\"full_backtest_results\", {})\n",
        "                metrics = full_results.get(\"backtest_results\")\n",
        "\n",
        "            # Accept either Polars or Pandas metrics (convert if needed)\n",
        "            if metrics is None:\n",
        "                avg_dd = float(\"inf\")\n",
        "            elif isinstance(metrics, pl.DataFrame):\n",
        "                avg_dd = _avg_drawdown_recent(metrics)\n",
        "            else:\n",
        "                try:\n",
        "                    import pandas as pd  # optional dependency\n",
        "                    if isinstance(metrics, pd.DataFrame):\n",
        "                        avg_dd = _avg_drawdown_recent(pl.from_pandas(metrics))\n",
        "                    else:\n",
        "                        avg_dd = float(\"inf\")\n",
        "                except Exception:\n",
        "                    avg_dd = float(\"inf\")\n",
        "\n",
        "            coefs[mname] = _coef_from_avg_dd(avg_dd)\n",
        "\n",
        "        # Normalize coefficients to sum to 1; if all zero, fall back to equal weight\n",
        "        total = sum(coefs.values())\n",
        "        if total <= _EPS:\n",
        "            n = float(len(model_insights))\n",
        "            coefs = {k: 1.0 / n for k in model_insights.keys()}\n",
        "        else:\n",
        "            coefs = {k: v / total for k, v in coefs.items()}\n",
        "\n",
        "        # 2) Scale each model's weights by its coefficient and combine\n",
        "        longs: List[LazyFrame] = []\n",
        "        for mname, lf in model_insights.items():\n",
        "            coef = coefs.get(mname, 0.0)\n",
        "\n",
        "            # Multiply all non-'date' columns by coef (robust across Polars versions)\n",
        "            names = lf.collect_schema().names()\n",
        "            wcols = [c for c in names if c != \"date\"]\n",
        "            if not wcols:\n",
        "                continue\n",
        "\n",
        "            scaled = lf.with_columns([(pl.col(c) * pl.lit(coef)).alias(c) for c in wcols])\n",
        "\n",
        "            # Use unpivot instead of melt (updated API)\n",
        "            long = scaled.unpivot(index=\"date\", variable_name=\"ticker\", value_name=\"w\")\n",
        "            longs.append(long)\n",
        "\n",
        "        if not longs:\n",
        "            return pl.DataFrame({\"date\": []}).lazy()\n",
        "\n",
        "        # 3) Sum across models in long space, pivot to wide\n",
        "        combined_long_lf = pl.concat(longs, how=\"vertical\").group_by([\"date\", \"ticker\"]).agg(\n",
        "            pl.col(\"w\").sum().alias(\"w\")\n",
        "        )\n",
        "\n",
        "        combined_wide_df = (\n",
        "            combined_long_lf\n",
        "            .collect(engine=\"streaming\")  # pivot is a DataFrame op in many Polars versions\n",
        "            .pivot(values=\"w\", index=\"date\", on=\"ticker\", aggregate_function=\"first\")\n",
        "            .sort(\"date\")\n",
        "        )\n",
        "        return combined_wide_df.lazy()\n",
        "\n",
        "    return run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2177b69-326f-460e-afe3-e7e7bf1d9811",
      "metadata": {},
      "outputs": [],
      "source": [
        "aggregator_registry = {\n",
        "    \"min_avg_drawdown\": {\n",
        "        \"function\": MinAvgDrawdownAggregator(window_days=252),\n",
        "        \"lookback\": 0,  # No additional lookback needed\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a9c4931-3bcb-4397-adf1-9c6cabfa52fa",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1) experiment config\n",
        "universe = [\n",
        "  \"SPY-US\", \"SLV-US\", \"GLD-US\", \"TLT-US\", \"USO-US\", \"UNG-US\", \"IXJ-US\",\n",
        "  \"KXI-US\", \"JXI-US\", \"IXG-US\", \"IXN-US\", \"RXI-US\", \"MXI-US\", \"EXI-US\",\n",
        "  \"IXC-US\", \"IEI-US\", \"SHY-US\", \"BIL-US\", \"JPXN-US\", \"INDA-US\", \"MCHI-US\",\n",
        "  \"EZU-US\", \"IBIT-US\", \"ETHA-US\", \"VIXY-US\"\n",
        "]\n",
        "features = [\"close_momentum_10\"]                   # must exist in FEATURES\n",
        "models   = [\"RXI_TLT_pml_10\", \"GLD_USO_nml_10\"]    # keys in MODELS\n",
        "aggregators = [\"min_avg_drawdown\"]                 # keys in aggregator_registry (custom)\n",
        "optimizers   = [\"mean_variance_constrained\"]       # keys in OPTIMIZERS (optional final stage)\n",
        "initial_value = 1_000_000\n",
        "start_date = datetime.date(2021, 1, 1)\n",
        "end_date = datetime.date(2025, 1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08b9907e-0bf2-4271-ba5c-be45a6e4bbf3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2) build model state + prices (cached locally)\n",
        "raw_data_bundle = read_data(include_supplemental=True)\n",
        "model_state_bundle, prices = create_model_state(\n",
        "    raw_data_bundle=raw_data_bundle,\n",
        "    features=features,\n",
        "    start_date=start_date,\n",
        "    end_date=end_date,\n",
        "    universe=universe\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfcda308-0dd6-47c8-9ec5-6a9ae1b41dc9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3) run model backtests + simulations\n",
        "model_insights = orchestrate_model_backtests(\n",
        "    model_state_bundle=model_state_bundle,\n",
        "    models=models,\n",
        "    universe=universe,\n",
        "    registry=MODELS  # pass in your custom models registry instead of pulling default prod registry\n",
        ")\n",
        "\n",
        "model_simulations = orchestrate_model_simulations(\n",
        "    prices=prices,\n",
        "    model_insights=model_insights,\n",
        "    start_date=start_date,\n",
        "    end_date=end_date\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec4478cf-3b31-4b9c-9ebe-04cc95656568",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4) aggregate + optimize portfolio and simulate\n",
        "aggregated_insights = orchestrate_portfolio_aggregation(\n",
        "    model_insights=model_insights,\n",
        "    backtest_results=model_simulations,\n",
        "    universe=universe,\n",
        "    aggregators=aggregators,\n",
        "    start_date=start_date,\n",
        "    end_date=end_date,\n",
        "    registry=aggregator_registry,  # Use custom aggregator registry\n",
        ")\n",
        "\n",
        "optimizer_insights = orchestrate_portfolio_optimizations(\n",
        "    prices=prices,\n",
        "    aggregated_insights=aggregated_insights,\n",
        "    universe=universe,\n",
        "    optimizers=optimizers,\n",
        ")\n",
        "\n",
        "optimizer_simulations = orchestrate_portfolio_simulations(\n",
        "    prices=prices,\n",
        "    portfolio_insights=optimizer_insights,\n",
        "    start_date=start_date,\n",
        "    end_date=end_date,\n",
        "    initial_value=initial_value,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f1c4024-9187-44ed-8133-312b4a7b4270",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5) visualize one result (example: mean_variance_constrained)\n",
        "optimizer_simulations[\"mean_variance_constrained\"][\"backtest_metrics\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90cd4bb7-3fa9-490b-b6de-541c65f0fec4",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2dbdde8-e094-45d4-9c63-f9f6b052f27f",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
